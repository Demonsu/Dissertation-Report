\chapter{Literature Review}

\section{Parser}

Parser combinator is not a grand new concept in compilation realm since the birth of functional languages. It takes the advantage of combinable functions offered by a functional language to enable a user to compose his own parsers. Nowadays almost all of the popular functional languages provide different kinds of parser combinator frameworks of their own to support flexible parsing requirements of domain specific languages. Hence, researches on parser combinator become one of the popular issues in functional programming languages. To design our own parser combinator for a new language F2J, we have conducted a series of literature reviews in the corresponding topics.

The first topic concerns the design philosophy of parser combinator frameworks. The basic and classical approach to compose a parser is the recursive descendant method. A recursive descendant parser designs a series of basic functions with non-terminals on the left-hand side. Each functions takes the string to be parsed, attempts to recognize some prefix or the input string as a derivation of the corresponding non-terminal and returns either a "success" or "failure" result \cite{Ford2002}. Although there are some implementation problems existing in this simple method such as left-recursion, all of these issues can be solved with some trivial modifications on the basic functions and then a top-down backtracking parser can be constructed \cite{Compilers:2006}. Based on this parser prototype, optimizations can be conducted to improve its efficiency on parsing complex inputs with complicated grammars. Ford has compared several optimization techniques in his paper, which includes prediction, tabular top-down parsing and packrat parsing \cite{Ford2002}. Packrat parsing provides simplicity and elegance of backtrack model and eliminates the risk of super-linear time at the meantime. Although packrat parsing has some deficiencies like no support toward non-deterministic parsing and consumption of spaces, it can be introduced into our work freely since F2J is a kind of deterministic and stateless language, and space restriction required by the parsing environment is not quite rigorous.

Another significant philosophy that conducts implementation of a parser with higher efficiency is the concept of a monad, an algebraic structure from mathematics that has proved useful for addressing a number of computational problems \cite{Hutton:1996}. Monads make it possible to build a pipeline that processes the data in steps by providing additional processing rules. Additionally, monadic parsers can also be expressed in a modular way in terms of two simpler monads and this expression can be processed recursively. Hence, it simplifies the way we design and describe a parser, and also improves the readability.

The second topic is the detailed implementation of parser combinators based on the philosophy introduced above. There are numerous kinds of excellent parser combinator frameworks today offered by various languages as is mentioned in the above sections. The most famous and efficient parser combinator framework is Parsec in Haskell \cite{Fokker:1995}. It extensively adopted the principal concepts described in Monadic philosophy, together with some classical compilation techniques such as LL(1) strategy and lookahead restrictions, which circumvents space leaks that may occur on a naive implementations. Parsec also demonstrates the weaknesses of parser combinators approach like inability of doing run-time grammar analyses.

Scala is another excellent choice to implement a domain specific language parser by combining the basic parsers provided by its parser combinator library. Moors et al \cite{Moors:2008} have provided a mini version of Scala parser combinator framework together with a detailed introduction of the original version. Scala's parser combinator framework offers both basic and high-level combinators for repetition, optionality, easy elimination of left-recursion and so on. Its implementation extensively uses Scala's functional programming features like case classes, pattern matching and call-by-name (lazy evaluation in Scala). Although Scala offers its own parser combinator framework, its efficiency is not competitive as those in other functional languages like Haskell, nor is faster than some parser generators like \textit{Yacc} and \textit{Bison}. The primary reasons, explained in \cite{Scala:2008}, are that it uses the primitive version of backtracking method without any optimization and it mixes up the parser construction and input analysis in the same set of operation so that each time a string is being parsed, a new parser will be generated instead of reusing the existing one. These two reasons, especially the latter one, occupy much of the computation time without reusing any of the work already done in previous runs. Besides, Scala is a universal language that adopts almost all kinds of programming paradigms like object-oriented and functional programming, and it runs on a Java virtual machine instead of an operating system directly. Therefore, its efficiency in processing functional programming is also not as good as other pure functional programming languages. Hence, there is grand space for efficiency promotion of Scala's parser combinator framework. We are to dig deeper into its library by researching and case studies, expecting to unearth something valuable to us in implementing our own library with F2J, and to avoid downsides concurrently.

\section{Pretty Printer}

Pretty printers are very common as many programming languages take it as a component. For example, \textit{LISP} uses only parentheses and spaces as delimiters, so a \textit{LISP} program will not be human-readable unless pretty printed. And any program which deals with symbolic data needs to display the structure of the data to the user at some point, whether it is a parser displaying internal structures for debugging or a text editor try to format a document.

However, the concept of 'pretty printer combinator' was not introduced until Hughes took it as an example when discussing how to design libraries of combinators \cite{hughes1995design}. Before that, the classic work in the scope of 'language independent pretty-printing' is Oppen's pretty-printer \cite{oppen1980prettyprinting}. His library consists of two parts, one is a small language defined by him for expressing documents, and another is an interpreter which users' pretty-printers need to be piped through it to generate the final pretty layout. The interpreter is written in an imperative language, and it's really very efficient. But it is quite large and its behavior on some inputs is hard to predict. Moreover it's not clear about how the interpreter chooses layouts and the interpreter also lacks extensibility. To solve all these problems of Oppen's pretty-printer, Hughes describes the evolution of a pretty printer library which designed as combinators and implemented in an algebraic way. Later the library was widely used and became a standard package in the Glasgow Haskell Compiler by Simon Peyton Jones (1997) \cite{jones1993glasgow}.

After that, research on pretty printer combinator were mostly based on Hughes's library. In his library, there are two distinct ways to concatenate documents, horizontal and vertical, with horizontal composition processing a right unit but no left unit, and vertical composition processing neither unit \cite{wadler2003prettier}. So concatenating documents in Hughes's library is complex and inefficient. Then Wadler solved the problem by designing a new library based on a single way to concatenate document, which is associative and has a left unit and right unit \cite{wadler2003prettier}. Wadler's library is 30\% shorter and runs 30\% faster than Hughes's \cite{wadler2003prettier}.





