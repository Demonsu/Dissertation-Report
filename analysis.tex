\chapter{Literature Review}

Parser combinator is not a grand new concept in compilation realm since the birth of functional languages. It takes the advantage of combinable functions offered by a functional language to enable a user to compose his own parsers. Nowadays almost all of the popular functional languages provide different kinds of parser combinator frameworks of their own to support flexible parsing requirements of domain specific languages. Hence, researches on parser combinator become one of the popular issues in functional programming languages. To design our own parser combinator for a new language F2J, we have conducted a series of literature reviews in the corresponding topics.

First topic concerns the design philosophy of parser combinator frameworks. The basic and classical approach to compose a parser is the recursive descendent method. A recursive descendent parser designs a series of basic functions with non-terminals on the left-hand side. Each functions takes the string to be parsed, attempts to recognise some prefix or the input string as a derivation of the corresponding non-terminal and returns either a "success" or "failure" result \cite{Ford2002}. Although there is some implementation problems existing in this simple method such as left-recursion, but they all can be solved with some trivial modification on the basic functions and then a top-down backtracking parser can be constructed \cite{Compilers:2006}. Based on this parser prototype, optimisations can be conducted to improve its efficiency on parsing complex source codes with complicated grammars. Bryan Ford has compared several optimisation techniques in his paper, which includes prediction, tabular top-down parsing and packrat parsing \cite{Ford2002}. Packrat parsing provides simplicity and elegance of backtrack model and eliminates the risk of super-linear time at the meantime. Although packrat parsing has some deficiencies like no support toward non-deterministic parsing and consumption of spaces, it can be introduced into our work freely since F2J is a kind of deterministic and stateless language, and space restriction required by the parsing environment is not quite rigorous.

Another significant philosophy that conducts implementation of a parser with higher efficiency is monad, an algebraic structure from mathematics that has proved useful for addressing a number of computational problems \cite{Hutton:1996}. Monad makes it possible to build a pipeline that processes the data in steps by providing additional processing rules. Additionally, monad parsers can also be expressed in a modular way in terms of two simpler monads and this expression can be processed recursively. Hence, it simplifies the way we design and describe a parser, and also improves the readability.

Second topic is the detailed implementation of parser combinators based on the philosophy introduced above. There are numerous kinds of excellent parser combinator frameworks today offered by various languages as is mentioned in the above sections. The most famous and efficient parser combinator framework is Parsec in Haskell \cite{Fokker:1995}. It extensively adopted the pricipal concepts described in Monadic philosophy, together with some classical compilation techniques such as LL(1) strategy and lookahead restricting, which circumvents space leak that may occur on a naive combinator and implements elegant error messages that help programmers to find out the problems. However, the implementation of Parsec also demonstrates the weaknesses of parser combinators approach like inability of run-time grammar analyse.

Scala is another excellent choice to implement a domain specific language parser by combining the basic parsers provided by its parser combinator library. Adriaan Moors, et al. have provided a mini version of Scala parser combinator framework together with a detailed introduction of the original version \cite{Moors:2008}. Scala's parser combinator framework offers both basic and high-level combinators for repetition, optionality, easy elimination of left-recursion and so on. Its implementation extensively uses Scala's functional programming features like case classes, pattern matching and call-by-name mechanism (lazy evaluation in Scala). Although Scala offers its own parser combinator framework, its efficiency is not competitive as those in other functional languages like Haskell, and nor is faster than some parser generators like Yacc and Bison. The primary reasons, explained in \cite{Scala:2008}, are that it uses the primitive version of backtracking method without any optimisation and it mixes up the parser construction and input analysis in the same set of operation so that each time a string is being parsed, a new parser will be generated instead of reuse the existing one. These two reasons, especially the latter one, occupy so much time in processing those works that have been processed in the former runs.  Besides, Scala is a universal language that adopts almost all kinds of programming paradigms like object-oriented and functional programming, and it runs on a Java virtual machine instead of an operating system directly. Therefore, its efficiency in processing functional programming is also not as good as other pure functional programming languages. Hence, there is grand space for efficiency promotion of Scala's parser combinator framework. We are to dig deeper into its library by researching and case studies, expecting to unearth something valuable to us in implementing our own library with F2J, and to avoid downsides concurrently.
